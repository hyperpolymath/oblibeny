// SPDX-License-Identifier: PMPL-1.0-or-later
// Copyright (c) 2024 Hyperpolymath

= Statistical Foundations for Security Analysis
:author: Oblibeny Project
:revdate: 2024
:toc: left
:toclevels: 4
:sectnums:
:stem: latexmath
:source-highlighter: rouge

== Abstract

This document develops the statistical methodology for security analysis of
oblivious computing systems. We cover hypothesis testing for security claims,
statistical distinguishers, and empirical validation frameworks.

== Hypothesis Testing Framework

=== Security as Hypothesis Test

Security games can be viewed as hypothesis tests:

* stem:[H_0]: System is secure (distributions are identical)
* stem:[H_1]: System is insecure (distributions differ)

The adversary is a statistical test trying to reject stem:[H_0].

=== Type I and Type II Errors

* **Type I (False Positive):** Rejecting stem:[H_0] when system is secure
* **Type II (False Negative):** Accepting stem:[H_0] when system is insecure

=== Security Advantage as Test Power

Adversary's advantage:
[stem]
++++
\text{Adv} = |P[\text{reject } H_0 | H_1] - P[\text{reject } H_0 | H_0]|
++++

Security requires stem:[\text{Adv} = \text{negl}(\lambda)].

== Statistical Distance

=== Definition: Total Variation Distance

For probability measures stem:[P, Q] on stem:[\Omega]:
[stem]
++++
d_{TV}(P, Q) = \sup_{A \subseteq \Omega} |P(A) - Q(A)| = \frac{1}{2} \sum_{\omega} |P(\omega) - Q(\omega)|
++++

=== Theorem: Coupling Characterization

[stem]
++++
d_{TV}(P, Q) = \min_{(X, Y): X \sim P, Y \sim Q} P[X \neq Y]
++++

.Proof
====
**Lower bound:** For any coupling, stem:[P[X \neq Y] \geq d_{TV}(P, Q)] by definition.

**Upper bound (optimal coupling):**
Construct stem:[(X, Y)] such that stem:[X = Y] with probability stem:[1 - d_{TV}].
Sample from the common part stem:[P \wedge Q] with probability stem:[1 - d_{TV}],
otherwise sample independently from the difference. ∎
====

=== Theorem: Data Processing Inequality (Statistical Version)

For any function stem:[f]:
[stem]
++++
d_{TV}(f(P), f(Q)) \leq d_{TV}(P, Q)
++++

== Statistical vs. Computational Security

=== Definition: Statistical Security

Scheme is stem:[\epsilon]-statistically secure if:
[stem]
++++
d_{TV}(\text{Real}, \text{Ideal}) \leq \epsilon
++++

=== Definition: Computational Security

Scheme is computationally secure if for all PPT stem:[\mathcal{A}]:
[stem]
++++
|\Pr[\mathcal{A}(\text{Real}) = 1] - \Pr[\mathcal{A}(\text{Ideal}) = 1]| \leq \text{negl}(\lambda)
++++

=== Relationship

[stem]
++++
\text{Statistical Security} \Rightarrow \text{Computational Security}
++++

The converse is false (pseudorandom generators).

== Distribution Testing

=== Uniformity Testing

Given samples stem:[x_1, \ldots, x_m] from unknown stem:[P] over stem:[[n]]:

**Null hypothesis:** stem:[P = U_n] (uniform)
**Alternative:** stem:[d_{TV}(P, U_n) \geq \epsilon]

=== Chi-Square Test

Test statistic:
[stem]
++++
\chi^2 = \sum_{i=1}^n \frac{(O_i - E_i)^2}{E_i}
++++

where stem:[O_i] = observed count, stem:[E_i = m/n] = expected count.

Under stem:[H_0], stem:[\chi^2 \sim \chi^2_{n-1}].

=== Theorem: Sample Complexity for Uniformity Testing

To distinguish uniform from stem:[\epsilon]-far with constant probability:
[stem]
++++
m = \Theta\left(\frac{\sqrt{n}}{\epsilon^2}\right)
++++

samples are necessary and sufficient.

=== Application: Testing ORAM Pattern Distribution

For ORAM with stem:[2^L] leaves:
* Null: Accessed leaves are uniform
* Test: Chi-square on observed leaf frequencies
* Required samples: stem:[O(\sqrt{2^L} / \epsilon^2)]

== Kolmogorov-Smirnov Test

=== One-Sample KS Test

For continuous distribution, test statistic:
[stem]
++++
D_n = \sup_x |F_n(x) - F(x)|
++++

where stem:[F_n] is empirical CDF.

=== Theorem: KS Convergence

Under stem:[H_0]:
[stem]
++++
\sqrt{n} D_n \xrightarrow{d} K
++++

where stem:[K] is the Kolmogorov distribution.

=== Application: Timing Analysis

Test whether ORAM access times follow expected distribution.

== Likelihood Ratio Tests

=== Neyman-Pearson Lemma

The most powerful test at level stem:[\alpha] rejects when:
[stem]
++++
\frac{L(x | H_1)}{L(x | H_0)} > k_\alpha
++++

=== Application: Optimal Distinguisher

For computational indistinguishability, the adversary should use
likelihood ratio if distributions were known.

=== Theorem: Distinguisher Advantage Bound

For PPT adversary without knowledge of distributions:
[stem]
++++
\text{Adv} \leq \text{Adv}_{\text{LR}} = d_{TV}(P_0, P_1)
++++

Computational security holds when stem:[d_{TV}] is negligible or
distributions are computationally close.

== Confidence Intervals

=== Definition: Confidence Interval

A stem:[(1-\alpha)] confidence interval for parameter stem:[\theta] is random interval stem:[[L, U]] such that:
[stem]
++++
P[\theta \in [L, U]] \geq 1 - \alpha
++++

=== Clopper-Pearson Interval (Exact Binomial)

For stem:[k] successes in stem:[n] trials:
[stem]
++++
L = B^{-1}(\alpha/2; k, n-k+1), \quad U = B^{-1}(1-\alpha/2; k+1, n-k)
++++

where stem:[B^{-1}] is the inverse beta CDF.

=== Application: Stash Overflow Probability

Estimate stem:[p = P[|\text{Stash}| > R]] from empirical observations.

== Bayesian Analysis

=== Bayes' Theorem for Security

Prior belief stem:[\pi_0(\theta)] updated by data stem:[x]:
[stem]
++++
\pi(\theta | x) = \frac{L(x | \theta) \pi_0(\theta)}{\int L(x | \theta') \pi_0(\theta') d\theta'}
++++

=== Cryptographic Prior

For security parameter stem:[\lambda], prior on adversary advantage:
[stem]
++++
\pi(\text{Adv}) = \text{Beta}(1, 2^\lambda)
++++

Reflects belief that advantage is likely negligible.

=== Posterior Probability of Security

After observing stem:[m] attack attempts, all unsuccessful:
[stem]
++++
P[\text{Adv} < 2^{-\lambda} | \text{data}] \to 1
++++

as stem:[m \to \infty].

== Sequential Analysis

=== Sequential Probability Ratio Test (SPRT)

At each observation, compute:
[stem]
++++
\Lambda_n = \frac{\prod_{i=1}^n L(x_i | H_1)}{\prod_{i=1}^n L(x_i | H_0)}
++++

Decide:
* stem:[\Lambda_n \geq B]: Accept stem:[H_1]
* stem:[\Lambda_n \leq A]: Accept stem:[H_0]
* stem:[A < \Lambda_n < B]: Continue sampling

=== Application: Early Detection of Attacks

Stop testing early when evidence strongly favors one hypothesis.

== Multiple Testing Correction

=== Bonferroni Correction

For stem:[m] simultaneous tests at level stem:[\alpha]:

Test each at level stem:[\alpha/m] to maintain family-wise error rate stem:[\alpha].

=== False Discovery Rate (FDR)

Benjamini-Hochberg procedure controls expected false discovery proportion.

=== Application: Testing Multiple ORAM Operations

When testing patterns for stem:[m] different operation types,
apply multiple testing correction.

== Empirical Process Theory

=== Glivenko-Cantelli Theorem

[stem]
++++
\sup_x |F_n(x) - F(x)| \xrightarrow{a.s.} 0
++++

=== Donsker's Theorem

[stem]
++++
\sqrt{n}(F_n - F) \xrightarrow{d} \mathbb{B}_F
++++

where stem:[\mathbb{B}_F] is a Brownian bridge.

=== Application: Asymptotic Security Analysis

Large-sample distribution of test statistics for security analysis.

== Bootstrap Methods

=== Non-parametric Bootstrap

For statistic stem:[T(X_1, \ldots, X_n)]:

1. Resample stem:[X_1^*, \ldots, X_n^*] with replacement
2. Compute stem:[T^* = T(X_1^*, \ldots, X_n^*)]
3. Repeat stem:[B] times
4. Use empirical distribution of stem:[T^*]

=== Application: Bandwidth Variability

Estimate variance of ORAM bandwidth empirically.

== Concentration Bounds for Security

=== McDiarmid's Inequality

If stem:[f(x_1, \ldots, x_n)] satisfies bounded differences:
[stem]
++++
|f(\ldots, x_i, \ldots) - f(\ldots, x'_i, \ldots)| \leq c_i
++++

Then:
[stem]
++++
P[f - \mathbb{E}[f] \geq t] \leq \exp\left(-\frac{2t^2}{\sum_i c_i^2}\right)
++++

=== Application: Stash Size Bound

Stash size after stem:[n] operations satisfies bounded differences.

== Random Matrix Theory

=== Marchenko-Pastur Law

For stem:[n \times p] random matrix stem:[X] with i.i.d. entries:

As stem:[n, p \to \infty] with stem:[p/n \to \gamma]:

[stem]
++++
\frac{1}{p} \text{tr}(X^T X) \xrightarrow{a.s.} 1
++++

=== Application: Position Map Analysis

Position map viewed as random matrix; spectral properties reveal structure.

== Order Statistics

=== Distribution of Order Statistics

For stem:[X_{(1)} \leq \cdots \leq X_{(n)}] from stem:[F]:

[stem]
++++
f_{X_{(k)}}(x) = \frac{n!}{(k-1)!(n-k)!} F(x)^{k-1} (1-F(x))^{n-k} f(x)
++++

=== Application: Timing Side Channels

Analyze minimum and maximum access times for side-channel leakage.

== Extreme Value Theory

=== Fisher-Tippett-Gnedenko Theorem

Properly normalized maxima converge to one of three distributions:
Gumbel, Fréchet, or Weibull.

=== Application: Worst-Case Analysis

Model distribution of maximum stash size or bandwidth.

== Survival Analysis

=== Kaplan-Meier Estimator

For time-to-event data with censoring:
[stem]
++++
\hat{S}(t) = \prod_{t_i \leq t} \left(1 - \frac{d_i}{n_i}\right)
++++

=== Application: Time to Security Failure

Model time until first successful attack (if any).

== Regression for Security Metrics

=== Linear Regression for Bandwidth

Model bandwidth as function of parameters:
[stem]
++++
\text{Bandwidth} = \beta_0 + \beta_1 \log N + \beta_2 Z + \epsilon
++++

=== Logistic Regression for Attack Success

[stem]
++++
\log \frac{P[\text{attack succeeds}]}{1 - P[\text{attack succeeds}]} = \beta_0 + \beta_1 \lambda + \epsilon
++++

== Simulation and Monte Carlo

=== Monte Carlo Security Estimation

Estimate stem:[P[\text{attack succeeds}]]:
[stem]
++++
\hat{p} = \frac{1}{M} \sum_{i=1}^M \mathbf{1}[\text{attack}_i \text{ succeeds}]
++++

Standard error: stem:[\sqrt{p(1-p)/M}]

=== Importance Sampling

For rare events (attacks succeeding):

Sample from proposal stem:[Q], weight by likelihood ratio:
[stem]
++++
\hat{p} = \frac{1}{M} \sum_{i=1}^M \frac{p(x_i)}{q(x_i)} \mathbf{1}[\text{attack}(x_i)]
++++

== Conclusion

Statistical methodology enables:

1. **Empirical validation** of security claims
2. **Quantification** of security margins
3. **Detection** of implementation flaws
4. **Confidence statements** about system security

== References

1. Lehmann, E. & Romano, J. (2005). "Testing Statistical Hypotheses." Springer.
2. Van der Vaart, A. (1998). "Asymptotic Statistics." Cambridge.
3. Canetti, R. & Goldreich, O. (1999). "Towards a Theory of Cryptographic Security."
4. DasGupta, A. (2008). "Asymptotic Theory of Statistics and Probability."

== TODO

// TODO: Add mixture model analysis for traffic patterns
// TODO: Develop sequential testing with adaptive adversaries
// TODO: Add survival analysis for time-bounded security
// TODO: Formalize differential privacy statistical framework
// TODO: Add non-parametric methods for distribution-free security
